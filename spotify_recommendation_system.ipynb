{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as px \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_o.csv\")\n",
    "genre_data = pd.read_csv('data_by_genres_o.csv')\n",
    "year_data = pd.read_csv('data_by_year_o.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to check for all the analysis with the target as 'popularity'. Before going to do that let's check for the Feature Correlation by considering a few features and for that, I'm going to use the yellowbrick package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.target import FeatureCorrelation\n",
    "\n",
    "feature_names = ['acousticness', 'danceability', 'energy', 'instrumentalness',\n",
    "       'liveness', 'loudness', 'speechiness', 'tempo', 'valence','duration_ms','explicit','key','mode','year']\n",
    "\n",
    "X, y = data[feature_names], data['popularity']\n",
    "\n",
    "# Create a list of the feature names\n",
    "features = np.array(feature_names)\n",
    "\n",
    "# Instantiate the visualizer\n",
    "visualizer = FeatureCorrelation(labels=features)\n",
    "\n",
    "plt.rcParams['figure.figsize']=(20,20)\n",
    "visualizer.fit(X, y)     # Fit the data to the visualizer\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding by Visualization and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music by Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the data grouped by year, we can understand how the overall sound of music has changed from 1921 to 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decade(year):\n",
    "    period_start = int(year/10) * 10\n",
    "    decade = '{}s'.format(period_start)\n",
    "    return decade\n",
    "\n",
    "data['decade'] = data['year'].apply(get_decade)\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11 ,6)})\n",
    "sns.countplot(data['decade'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Genres with K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I used simple K-means clustering algorithm to divide the genres in this dataset into ten clusters based on the numerical audio features of each genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Finding the Optimal Number of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "kmeans = KMeans()\n",
    "visualizer = KElbowVisualizer(kmeans, k=(2,20))\n",
    "visualizer.fit(X) \n",
    "visualizer.poof()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the decrease in the fit time and distortion score. We choose 10 as k. We may choose 5 but it would be little bit less for genres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "cluster_pipeline = Pipeline([('scaler', StandardScaler()), ('kmeans', KMeans(n_clusters=10, n_jobs=-1))])\n",
    "X = genre_data.select_dtypes(np.number)\n",
    "cluster_pipeline.fit(X)\n",
    "genre_data['cluster'] = cluster_pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Clusters with t-SNE\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne_pipeline = Pipeline([('scaler', StandardScaler()), ('tsne', TSNE(n_components=2, verbose=2))])\n",
    "genre_embedding = tsne_pipeline.fit_transform(X)\n",
    "projection = pd.DataFrame(columns=['x', 'y'], data=genre_embedding)\n",
    "projection['genres'] = genre_data['genres']\n",
    "projection['cluster'] = genre_data['cluster']\n",
    "\n",
    "fig = px.scatter(\n",
    "    projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'genres'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Songs with K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "kmeans = KMeans()\n",
    "visualizer = KElbowVisualizer(kmeans, k=(2,20))\n",
    "visualizer.fit(X) \n",
    "visualizer.poof()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose 20 as k. We might choose 13 or anything else but it would be little bit less for all the songs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.3s\n",
      "Initialization complete\n",
      "Iteration 0, inertia 1559979.8019470547\n",
      "...",
      "Converged at iteration 37: center shift 8.206930591686624e-05 within tolerance 0.00010000000000000789.\n",
      "[Pipeline] ............ (step 2 of 2) Processing kmeans, total=  40.3s\n"
     ]
    }
   ],
   "source": [
    "song_cluster_pipeline = Pipeline([('scaler', StandardScaler()), \n",
    "                                  ('kmeans', KMeans(n_clusters=20, \n",
    "                                   verbose=2, n_jobs=4))],verbose=True)\n",
    "\n",
    "X = data.select_dtypes(np.number)\n",
    "number_cols = list(X.columns)\n",
    "song_cluster_pipeline.fit(X)\n",
    "song_cluster_labels = song_cluster_pipeline.predict(X)\n",
    "data['cluster_label'] = song_cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Clusters with PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_pipeline = Pipeline([('scaler', StandardScaler()), ('PCA', PCA(n_components=2))])\n",
    "song_embedding = pca_pipeline.fit_transform(X)\n",
    "projection = pd.DataFrame(columns=['x', 'y'], data=song_embedding)\n",
    "projection['title'] = data['name']\n",
    "projection['cluster'] = data['cluster_label']\n",
    "\n",
    "fig = px.scatter(\n",
    "    projection, x='x', y='y', color='cluster', hover_data=['x', 'y', 'title'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the RecSys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Based on the applications, it can be seen that similar genres are likely to have data points that are located close to each other while similar types of songs are also clustered together.\n",
    "* This observation makes  sense. Similar genres will sound similar and will come from similar time periods while the same can be said for songs within those genres. This can be used to build a recommendation system by taking the data points of the songs a user has listened to and recommending songs corresponding to nearby data points.\n",
    "* Spotipy is a Python client for the Spotify Web API that makes it easy for developers to fetch data and query Spotify’s catalog for songs. We have to install using pip install spotipy\n",
    "* After installing Spotipy, we will need to create an app on the Spotify Developer’s page and save your Client ID and secret key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from collections import defaultdict\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=os.environ['SPOTIPY_CLIENT_ID'],\n",
    "                                                           client_secret=os.environ['SPOTIPY_CLIENT_SECRET']))\n",
    "\n",
    "def find_song(name, year):\n",
    "    song_data = defaultdict()\n",
    "    results = sp.search(q= 'track: {} year: {}'.format(name,year), limit=1)\n",
    "    if results['tracks']['items'] == []:\n",
    "        return None\n",
    "\n",
    "    results = results['tracks']['items'][0]\n",
    "    track_id = results['id']\n",
    "    audio_features = sp.audio_features(track_id)[0]\n",
    "\n",
    "    song_data['name'] = [name]\n",
    "    song_data['year'] = [year]\n",
    "    song_data['explicit'] = [int(results['explicit'])]\n",
    "\n",
    "    song_data['duration_ms'] = [results['duration_ms']]\n",
    "    song_data['popularity'] = [results['popularity']]\n",
    "\n",
    "    for key, value in audio_features.items():\n",
    "        song_data[key] = value\n",
    "\n",
    "    return pd.DataFrame(song_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "import difflib\n",
    "\n",
    "number_cols = ['valence', 'year', 'acousticness', 'danceability', 'duration_ms', 'energy', 'explicit',\n",
    " 'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'popularity', 'speechiness', 'tempo']\n",
    "\n",
    "\n",
    "def get_song_data(song, spotify_data):\n",
    "    \n",
    "    try:\n",
    "        song_data = spotify_data[(spotify_data['name'] == song['name']) \n",
    "                                & (spotify_data['year'] == song['year'])].iloc[0]\n",
    "        return song_data\n",
    "    \n",
    "    except IndexError:\n",
    "        return find_song(song['name'], song['year'])\n",
    "        \n",
    "\n",
    "def get_mean_vector(song_list, spotify_data):\n",
    "    \n",
    "    song_vectors = []\n",
    "    \n",
    "    for song in song_list:\n",
    "        song_data = get_song_data(song, spotify_data)\n",
    "        if song_data is None:\n",
    "            print('Warning: {} does not exist in Spotify or in database'.format(song['name']))\n",
    "            continue\n",
    "        song_vector = song_data[number_cols].values\n",
    "        song_vectors.append(song_vector)  \n",
    "    \n",
    "    song_matrix = np.array(list(song_vectors))\n",
    "    return np.mean(song_matrix, axis=0)\n",
    "\n",
    "\n",
    "def flatten_dict_list(dict_list):\n",
    "    \n",
    "    flattened_dict = defaultdict()\n",
    "    for key in dict_list[0].keys():\n",
    "        flattened_dict[key] = []\n",
    "    \n",
    "    for dictionary in dict_list:\n",
    "        for key, value in dictionary.items():\n",
    "            flattened_dict[key].append(value)\n",
    "            \n",
    "    return flattened_dict\n",
    "\n",
    "\n",
    "def recommend_songs( song_list, spotify_data, n_songs=10):\n",
    "    \n",
    "    metadata_cols = ['name', 'year', 'artists']\n",
    "    song_dict = flatten_dict_list(song_list)\n",
    "    \n",
    "    song_center = get_mean_vector(song_list, spotify_data)\n",
    "    scaler = song_cluster_pipeline.steps[0][1]\n",
    "    scaled_data = scaler.transform(spotify_data[number_cols])\n",
    "    scaled_song_center = scaler.transform(song_center.reshape(1, -1))\n",
    "    distances = cdist(scaled_song_center, scaled_data, 'cosine')\n",
    "    index = list(np.argsort(distances)[:, :n_songs][0])\n",
    "    \n",
    "    rec_songs = spotify_data.iloc[index]\n",
    "    rec_songs = rec_songs[~rec_songs['name'].isin(song_dict['name'])]\n",
    "    return rec_songs[metadata_cols].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Helena Beat', 'year': 2011, 'artists': \"['Foster The People']\"},\n",
       " {'name': 'The Riddle', 'year': 2006, 'artists': '[\"Gigi D\\'Agostino\"]'},\n",
       " {'name': 'Hail to the King',\n",
       "  'year': 2013,\n",
       "  'artists': \"['Avenged Sevenfold']\"},\n",
       " {'name': 'You Were Right', 'year': 2016, 'artists': \"['RÜFÜS DU SOL']\"},\n",
       " {'name': 'Sadi Gali', 'year': 2011, 'artists': \"['Lehmber Hussainpuri']\"},\n",
       " {'name': 'Sugar (feat. Francesco Yates)',\n",
       "  'year': 2015,\n",
       "  'artists': \"['Robin Schulz', 'Francesco Yates']\"},\n",
       " {'name': 'La Planta', 'year': 2014, 'artists': \"['Caos']\"},\n",
       " {'name': 'Summer', 'year': 2014, 'artists': \"['Calvin Harris']\"},\n",
       " {'name': 'The One', 'year': 1999, 'artists': \"['Backstreet Boys']\"},\n",
       " {'name': \"DJ Got Us Fallin' In Love (feat. Pitbull)\",\n",
       "  'year': 2010,\n",
       "  'artists': \"['Usher', 'Pitbull']\"}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_songs([{'name': 'Lucky Star', 'year':1983},\n",
    "                {'name': 'Round Round', 'year': 2002},\n",
    "                {'name': 'Give It Away', 'year': 1991},\n",
    "                {'name': 'Strict Machine', 'year': 2003},\n",
    "                {'name': 'Smile Like You Mean It', 'year': 2004}],  data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final cell will give you a recommendation list of songs like this. You can change the songs if you want."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
